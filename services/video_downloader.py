import os
import requests
import re
from urllib.parse import urlparse
import yt_dlp
import subprocess
import json
from typing import List, Dict
from .kuaishou_downloader import KuaishouDownloader
from .xiaohongshu_downloader import XiaohongshuDownloader

# Debug logging
def debug_log(message):
    """Write debug messages to a file"""
    with open('debug_log.txt', 'a', encoding='utf-8') as f:
        f.write(f"{message}\n")

def sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤æˆ–æ›¿æ¢Windowsæ–‡ä»¶ç³»ç»Ÿä¸æ”¯æŒçš„å­—ç¬¦
    """
    if not filename:
        return filename

    # Windowsæ–‡ä»¶ç³»ç»Ÿä¸å…è®¸çš„å­—ç¬¦: < > : " | ? * ä»¥åŠæ§åˆ¶å­—ç¬¦
    # æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
    invalid_chars = r'[<>:"|?*\x00-\x1f]'
    filename = re.sub(invalid_chars, '_', filename)

    # ç§»é™¤è¿ç»­çš„ç©ºæ ¼å’Œç‚¹
    filename = re.sub(r'[.\s]+', '_', filename)

    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºæ ¼å’Œç‚¹
    filename = filename.strip(' .')

    # é™åˆ¶æ–‡ä»¶åé•¿åº¦ï¼ˆWindowsé€šå¸¸é™åˆ¶ä¸º260ä¸ªå­—ç¬¦ï¼Œä½†è·¯å¾„ä¹Ÿä¼šå ç”¨é•¿åº¦ï¼‰
    if len(filename) > 100:
        filename = filename[:100]

    return filename

class VideoDownloader:
    def __init__(self):
        # ä½¿ç”¨å›ºå®šçš„ä¸´æ—¶ç›®å½•å­˜å‚¨ä¸‹è½½çš„æ–‡ä»¶ï¼Œé¿å…Flaské‡å¯æ—¶è·¯å¾„å¤±æ•ˆ
        import tempfile
        import os

        # ä½¿ç”¨å›ºå®šçš„ä¸´æ—¶ç›®å½•ï¼Œè€Œä¸æ˜¯æ¯æ¬¡åˆ›å»ºæ–°çš„
        self.temp_dir = os.path.join(tempfile.gettempdir(), 'fastmedia_temp')
        os.makedirs(self.temp_dir, exist_ok=True)

        self.download_dir = 'downloads/videos'  # ä¿ç•™ä½œä¸ºé»˜è®¤ä¸‹è½½ç›®å½•
        os.makedirs(self.download_dir, exist_ok=True)

        # åˆå§‹åŒ–å¿«æ‰‹å’Œå°çº¢ä¹¦ä¸‹è½½å™¨
        self.kuaishou_downloader = KuaishouDownloader(self.temp_dir)
        self.xiaohongshu_downloader = XiaohongshuDownloader(self.temp_dir)

        # yt-dlpåŸºç¡€é…ç½®
        self.ydl_opts = {
            'outtmpl': os.path.join(self.temp_dir, '%(extractor)s-%(title)s.%(ext)s'),
            'format': 'best[height<=720]/best[height<=480]/best/worst',  # æ›´çµæ´»çš„æ ¼å¼é€‰æ‹©
            'writeinfojson': False,
            'writesubtitles': False,
            'writeautomaticsub': False,
            'ignoreerrors': False,
            'no_warnings': False,
            'extractflat': False,
            'writethumbnail': False,
            'writeinfojson': False,
            'cookiefile': None,
            'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        }

    def get_bilibili_opts(self, base_opts: dict = None, download_mode: bool = True) -> dict:
        """è·å–Bç«™ä¸“ç”¨çš„yt-dlpé…ç½®"""
        if base_opts is None:
            base_opts = {}

        bilibili_opts = base_opts.copy()
        bilibili_opts.update({
            'noplaylist': True,     # ä¸ä¸‹è½½æ’­æ”¾åˆ—è¡¨ï¼Œåªä¸‹è½½å•ä¸ªè§†é¢‘
            'playlistend': 1,       # å¦‚æœæ˜¯æ’­æ”¾åˆ—è¡¨ï¼Œåªä¸‹è½½ç¬¬ä¸€ä¸ªè§†é¢‘
            'ignoreerrors': True,   # å¿½ç•¥é”™è¯¯ç»§ç»­å¤„ç†
            'no_warnings': True,    # ä¸æ˜¾ç¤ºè­¦å‘Š
            'retries': 3,           # é‡è¯•æ¬¡æ•°
            'socket_timeout': 30,   # socketè¶…æ—¶æ—¶é—´
            'fragment_retries': 5,  # ç‰‡æ®µé‡è¯•æ¬¡æ•°
            'skip_unavailable_fragments': True,  # è·³è¿‡ä¸å¯ç”¨çš„ç‰‡æ®µ
        })

        # å¦‚æœæ˜¯ä¸‹è½½æ¨¡å¼ï¼Œæ·»åŠ é¢å¤–çš„é…ç½®
        if download_mode:
            bilibili_opts.update({
                'format': '30032+30232/30016+30232/best[height<=480]+bestaudio/best',  # é€‰æ‹©480pè§†é¢‘+éŸ³é¢‘æˆ–æœ€ä½³ç»„åˆ
                'writeinfojson': False,
                'writesubtitles': False,
                'writeautomaticsub': False,
                'writethumbnail': False,
            })

        return bilibili_opts
    
    def download_batch(self, urls: List[str]) -> List[Dict]:
        """æ‰¹é‡ä¸‹è½½è§†é¢‘"""
        results = []
        
        for url in urls:
            try:
                result = self.download_single(url)
                results.append(result)
            except Exception as e:
                results.append({
                    'url': url,
                    'status': 'error',
                    'error': str(e),
                    'filepath': None
                })
        
        return results
    
    def download_single(self, url: str) -> Dict:
        """ä¸‹è½½å•ä¸ªè§†é¢‘"""
        try:
            debug_log(f"DEBUG: download_single called with URL: {url}")
            # é¢„å¤„ç†URLï¼ˆå¤„ç†çŸ­é“¾æ¥ç­‰ï¼‰
            processed_url = self.preprocess_url(url)
            debug_log(f"DEBUG: processed_url: {processed_url}")

            # æ£€æµ‹å¹³å°
            platform = self.detect_platform(processed_url)
            debug_log(f"DEBUG: detected platform: {platform}")

            if platform == 'unsupported':
                raise Exception(f'ä¸æ”¯æŒçš„å¹³å°: {url}')
            elif platform == 'kuaishou':
                # ä½¿ç”¨ä¸“é—¨çš„å¿«æ‰‹ä¸‹è½½å™¨
                return self.kuaishou_downloader.download_video(processed_url)
            elif platform == 'xiaohongshu':
                # ä½¿ç”¨ä¸“é—¨çš„å°çº¢ä¹¦ä¸‹è½½å™¨
                return self.xiaohongshu_downloader.download_video(processed_url)
            
            # æ ¹æ®å¹³å°è°ƒæ•´é…ç½®
            if platform == 'bilibili':
                # ä½¿ç”¨ç»Ÿä¸€çš„Bç«™é…ç½®
                opts = self.get_bilibili_opts(self.ydl_opts, download_mode=True)
            elif platform == 'douyin/tiktok':
                # TikTokç‰¹æ®Šé…ç½®
                opts = self.ydl_opts.copy()
                opts['format'] = 'best/worst'
                opts['http_headers'] = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Referer': 'https://www.tiktok.com/'
                }
            elif platform == 'kuaishou':
                # å¿«æ‰‹ç‰¹æ®Šé…ç½®
                opts = self.ydl_opts.copy()
                opts['format'] = 'best/worst'
                opts['http_headers'] = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Referer': 'https://www.kuaishou.com/',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br'
                }
                opts['extractor_args'] = {
                    'kuaishou': {
                        'api_hostname': 'www.kuaishou.com'
                    }
                }
                opts['cookiefile'] = None
                opts['ignoreerrors'] = True
            elif platform == 'xiaohongshu':
                # å°çº¢ä¹¦ç‰¹æ®Šé…ç½® - å¢å¼ºç‰ˆæœ¬ï¼Œæ·»åŠ æ›´å¤šæµè§ˆå™¨æ¨¡æ‹Ÿå¤´
                opts = {
                    'quiet': True,
                    'no_warnings': True,
                    'format': 'best/worst',
                    'http_headers': {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Referer': 'https://www.xiaohongshu.com/',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Cache-Control': 'no-cache',
                        'Pragma': 'no-cache',
                        'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                        'Sec-Ch-Ua-Mobile': '?0',
                        'Sec-Ch-Ua-Platform': '"Windows"',
                        'Sec-Fetch-Dest': 'document',
                        'Sec-Fetch-Mode': 'navigate',
                        'Sec-Fetch-Site': 'none',
                        'Sec-Fetch-User': '?1',
                        'Upgrade-Insecure-Requests': '1'
                    }
                }
                debug_log(f"DEBUG: å°çº¢ä¹¦é…ç½® - ä½¿ç”¨å¢å¼ºçš„æµè§ˆå™¨æ¨¡æ‹Ÿé…ç½®: {opts}")
            else:
                # å…¶ä»–å¹³å°ï¼ˆYouTubeç­‰ï¼‰ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œä½†éœ€è¦å¤„ç†æ–‡ä»¶åç¼–ç é—®é¢˜
                opts = self.ydl_opts.copy()

                # é’ˆå¯¹YouTubeçš„æ–‡ä»¶åç¼–ç é—®é¢˜ï¼Œä½¿ç”¨ASCIIæ–‡ä»¶å
                if platform in ['youtube', 'youtu.be']:
                    # åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„outtmplæ¥å¤„ç†æ–‡ä»¶åç¼–ç é—®é¢˜
                    # ä½¿ç”¨æ—¶é—´æˆ³å’ŒIDæ¥é¿å…ä¸­æ–‡å­—ç¬¦å¯¼è‡´çš„æ–‡ä»¶ç³»ç»Ÿé—®é¢˜
                    opts['outtmpl'] = os.path.join(self.temp_dir, 'youtube-%(id)s-%(timestamp)s.%(ext)s')
                    debug_log(f"DEBUG: YouTubeä½¿ç”¨ç‰¹æ®Šæ–‡ä»¶åæ¨¡æ¿: {opts['outtmpl']}")
            
            # ä½¿ç”¨yt-dlpä¸‹è½½
            try:
                debug_log(f"DEBUG: å¼€å§‹æå–å°çº¢ä¹¦è§†é¢‘ä¿¡æ¯ - URL: {processed_url}")
                debug_log(f"DEBUG: ä½¿ç”¨çš„yt-dlpé…ç½®: {opts}")

                # é’ˆå¯¹å°çº¢ä¹¦ä½¿ç”¨ä¸æµ‹è¯•è„šæœ¬å®Œå…¨ç›¸åŒçš„æ–¹å¼
                if platform == 'xiaohongshu':
                    debug_log(f"DEBUG: ä½¿ç”¨ä¸æµ‹è¯•è„šæœ¬å®Œå…¨ç›¸åŒçš„æ–¹å¼å¤„ç†å°çº¢ä¹¦")
                    try:
                        # å®Œå…¨å¤åˆ¶æµ‹è¯•è„šæœ¬çš„é€»è¾‘
                        xiaohongshu_opts = {
                            'quiet': True,
                            'no_warnings': True,
                            'format': 'best/worst',
                            'http_headers': {
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                                'Referer': 'https://www.xiaohongshu.com/',
                                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                                'Accept-Encoding': 'gzip, deflate, br'
                            }
                        }

                        debug_log(f"DEBUG: å°çº¢ä¹¦æµ‹è¯•è„šæœ¬é…ç½®: {xiaohongshu_opts}")

                        with yt_dlp.YoutubeDL(xiaohongshu_opts) as ydl:
                            debug_log(f"DEBUG: å¼€å§‹ä½¿ç”¨ä¸æµ‹è¯•è„šæœ¬ç›¸åŒçš„æ–¹å¼æå–ä¿¡æ¯")
                            info = ydl.extract_info(processed_url, download=False)
                            debug_log(f"DEBUG: å°çº¢ä¹¦æµ‹è¯•è„šæœ¬æ–¹å¼è·å–åˆ°çš„ä¿¡æ¯: {info}")

                        if info is None:
                            debug_log(f"DEBUG: å°çº¢ä¹¦æµ‹è¯•è„šæœ¬æ–¹å¼è¿”å›None")
                            raise Exception('æ— æ³•è·å–è§†é¢‘ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–è§†é¢‘ä¸å­˜åœ¨')

                    except Exception as e:
                        debug_log(f"DEBUG: å°çº¢ä¹¦æµ‹è¯•è„šæœ¬æ–¹å¼å¤±è´¥: {str(e)}")
                        raise Exception(f'å°çº¢ä¹¦è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}')
                else:
                    # å…¶ä»–å¹³å°ä½¿ç”¨åŸæœ‰çš„yt-dlp Python API
                    debug_log(f"DEBUG: å³å°†åˆ›å»ºYoutubeDLå®ä¾‹")
                    with yt_dlp.YoutubeDL(opts) as ydl:
                        debug_log(f"DEBUG: YoutubeDLå®ä¾‹åˆ›å»ºæˆåŠŸï¼Œå¼€å§‹æå–ä¿¡æ¯")
                        # è·å–è§†é¢‘ä¿¡æ¯
                        info = ydl.extract_info(processed_url, download=False)
                        debug_log(f"DEBUG: æå–åˆ°çš„è§†é¢‘ä¿¡æ¯: {info}")

                        # æ£€æŸ¥infoæ˜¯å¦ä¸ºNone
                        if info is None:
                            debug_log(f"DEBUG: è§†é¢‘ä¿¡æ¯æå–å¤±è´¥ - infoä¸ºNone")
                            raise Exception('æ— æ³•è·å–è§†é¢‘ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–è§†é¢‘ä¸å­˜åœ¨')

                    # ä¸‹è½½è§†é¢‘
                if platform == 'xiaohongshu':
                    # å°çº¢ä¹¦ä½¿ç”¨subprocessä¸‹è½½
                    debug_log(f"DEBUG: ä½¿ç”¨subprocessä¸‹è½½å°çº¢ä¹¦è§†é¢‘")
                    download_opts = opts.copy()
                    download_opts['outtmpl'] = os.path.join(self.temp_dir, '%(extractor)s-%(title)s.%(ext)s')

                    # æ„å»ºä¸‹è½½å‘½ä»¤
                    cmd = [
                        'python', '-m', 'yt_dlp',
                        '--quiet', '--no-warnings',
                        '--format', 'best/worst',
                        '--output', os.path.join(self.temp_dir, '%(extractor)s-%(title)s.%(ext)s'),
                        processed_url
                    ]
                    debug_log(f"DEBUG: å°çº¢ä¹¦ä¸‹è½½å‘½ä»¤: {' '.join(cmd)}")

                    try:
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                        debug_log(f"DEBUG: å°çº¢ä¹¦ä¸‹è½½è¿”å›ç : {result.returncode}")
                        debug_log(f"DEBUG: å°çº¢ä¹¦ä¸‹è½½è¾“å‡º: {result.stdout}")
                        debug_log(f"DEBUG: å°çº¢ä¹¦ä¸‹è½½é”™è¯¯: {result.stderr}")

                        if result.returncode != 0:
                            error_msg = result.stderr.strip() if result.stderr else 'ä¸‹è½½å¤±è´¥'
                            raise Exception(f'å°çº¢ä¹¦è§†é¢‘ä¸‹è½½å¤±è´¥: {error_msg}')

                        debug_log(f"DEBUG: å°çº¢ä¹¦è§†é¢‘ä¸‹è½½å®Œæˆ")
                    except subprocess.TimeoutExpired:
                        raise Exception('å°çº¢ä¹¦è§†é¢‘ä¸‹è½½è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•')
                else:
                    # å…¶ä»–å¹³å°çš„ä¸‹è½½é€»è¾‘
                    title = info.get('title', 'unknown')
                    # é’ˆå¯¹Bç«™ç‰¹æ®Šå¤„ç†
                    if platform == 'bilibili':
                        try:
                            # ä¸‹è½½è§†é¢‘
                            ydl.download([processed_url])
                        except Exception as download_error:
                            error_msg = str(download_error).lower()
                            print(f"Bç«™ä¸‹è½½é”™è¯¯è¯¦æƒ…: {str(download_error)}")

                            if 'json' in error_msg or 'parse' in error_msg:
                                raise Exception('Bç«™APIé™åˆ¶ï¼šè¯¥è§†é¢‘æš‚æ—¶æ— æ³•ä¸‹è½½ï¼Œè¯·ç¨åé‡è¯•æˆ–å°è¯•å…¶ä»–è§†é¢‘')
                            elif 'region' in error_msg or 'geoblock' in error_msg:
                                raise Exception('è¯¥è§†é¢‘æœ‰åœ°åŒºé™åˆ¶ï¼Œæ— æ³•åœ¨å½“å‰åœ°åŒºä¸‹è½½')
                            elif 'private' in error_msg or 'permission' in error_msg:
                                raise Exception('è¯¥è§†é¢‘ä¸ºç§äººè§†é¢‘æˆ–éœ€è¦æƒé™æ‰èƒ½ä¸‹è½½')
                            elif 'playlist' in error_msg:
                                raise Exception('Bç«™ç³»åˆ—è§†é¢‘å¤„ç†å¤±è´¥ï¼Œè¯·å°è¯•è§†é¢‘çš„å…·ä½“åˆ†é›†é“¾æ¥')
                            elif 'timeout' in error_msg or 'network' in error_msg:
                                raise Exception('ç½‘ç»œè¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•')
                            elif 'unavailable' in error_msg:
                                raise Exception('è¯¥è§†é¢‘ä¸å¯ç”¨ï¼Œå¯èƒ½å·²è¢«åˆ é™¤æˆ–è®¾ä¸ºç§å¯†')
                            else:
                                raise Exception(f'Bç«™ä¸‹è½½å¤±è´¥: {str(download_error)}')
                    else:
                        # å…¶ä»–å¹³å°æ­£å¸¸ä¸‹è½½
                        ydl.download([processed_url])

                # æ„å»ºæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«å¹³å°ä¿¡æ¯ï¼‰
                extractor = info.get('extractor', platform.replace('/', '_'))
                original_title = info.get('title', 'unknown')

                # é’ˆå¯¹YouTubeä½¿ç”¨ç‰¹æ®Šæ–‡ä»¶åå¤„ç†
                if platform in ['youtube', 'youtu.be']:
                    # YouTubeä½¿ç”¨çš„æ˜¯ youtube-%(id)s-%(timestamp)s.%(ext)s æ ¼å¼
                    # è¿™ä¸outtmplè®¾ç½®ä¿æŒä¸€è‡´
                    video_id = info.get('id', 'unknown')
                    import time
                    timestamp = int(time.time())
                    extension = info.get('ext', 'mp4')
                    filename = f"youtube-{video_id}-{timestamp}.{extension}"
                    # å¯¹äºä¸‹è½½æ–‡ä»¶åï¼Œä½¿ç”¨æ¸…ç†è¿‡çš„åŸå§‹æ ‡é¢˜
                    download_filename = f"youtube-{sanitize_filename(original_title)}.{extension}"
                else:
                    # å…¶ä»–å¹³å°ä½¿ç”¨åŸæœ‰é€»è¾‘ï¼Œä½†æ˜¯è¦ä½¿ç”¨sanitize_filenameæ¸…ç†æ ‡é¢˜
                    filename = f"{extractor}-{sanitize_filename(original_title)}.{info.get('ext', 'mp4')}"
                    download_filename = filename

                # å®é™…ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„åœ¨ä¸´æ—¶ç›®å½•ä¸­
                actual_filepath = os.path.join(self.temp_dir, filename)

                return {
                    'url': url,  # è¿”å›åŸå§‹URL
                    'processed_url': processed_url,  # è¿”å›å¤„ç†åçš„URL
                    'status': 'success',
                    'title': info.get('title', 'unknown'),
                    'platform': platform,
                    'temp_filepath': actual_filepath,  # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                    'download_filename': download_filename,  # å»ºè®®çš„æ–‡ä»¶å
                    'filesize': os.path.getsize(actual_filepath) if os.path.exists(actual_filepath) else 0,
                    'duration': info.get('duration', 0),
                    'uploader': info.get('uploader', '')
                }

            except Exception as e:
                # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                error_msg = str(e)
                debug_log(f"DEBUG: yt-dlpå¼‚å¸¸: {error_msg}")
                if 'NoneType' in error_msg and 'get' in error_msg:
                    raise Exception('Bç«™è§†é¢‘ä¿¡æ¯è·å–å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–Bç«™APIé™åˆ¶')
                elif 'æ— æ³•è·å–è§†é¢‘ä¿¡æ¯' in error_msg:
                    raise Exception('æ— æ³•è·å–è§†é¢‘ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–è§†é¢‘ä¸å­˜åœ¨')
                else:
                    raise Exception(f'ä¸‹è½½å¤±è´¥: {error_msg}')
        except Exception as e:
            # æ•è· download_single æ–¹æ³•çš„å…¶ä»–é”™è¯¯
            debug_log(f"DEBUG: download_singleå¼‚å¸¸: {str(e)}")
            raise Exception(f'è§†é¢‘ä¸‹è½½å¤±è´¥: {str(e)}')

    def cleanup_temp_file(self, filepath: str):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(filepath):
                os.remove(filepath)
                print(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {filepath}")
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

    def get_temp_file_info(self, filepath: str) -> dict:
        """è·å–ä¸´æ—¶æ–‡ä»¶ä¿¡æ¯"""
        try:
            if os.path.exists(filepath):
                stat = os.stat(filepath)
                return {
                    'exists': True,
                    'size': stat.st_size,
                    'modified_time': stat.st_mtime
                }
            else:
                return {'exists': False}
        except Exception as e:
            return {'exists': False, 'error': str(e)}

    def detect_platform(self, url: str) -> str:
        """æ£€æµ‹è§†é¢‘å¹³å°"""
        domain = urlparse(url).netloc.lower()

        if 'douyin.com' in domain or 'tiktok.com' in domain:
            return 'douyin/tiktok'
        elif 'bilibili.com' in domain or 'b23.tv' in domain:
            return 'bilibili'
        elif 'youtube.com' in domain or 'youtu.be' in domain:
            return 'youtube'
        elif 'twitter.com' in domain or 'x.com' in domain:
            return 'twitter'
        elif 'kuaishou.com' in domain:
            return 'kuaishou'
        elif 'xiaohongshu.com' in domain or 'xhslink.com' in domain:
            return 'xiaohongshu'
        else:
            return 'unsupported'

    def preprocess_url(self, url: str) -> str:
        """é¢„å¤„ç†URLï¼Œå¤„ç†çŸ­é“¾æ¥é‡å®šå‘å’Œæ¸…ç†å‚æ•°ç­‰"""
        try:
            # å¤„ç†URLä¸­çš„åˆ†äº«æ–‡æœ¬ï¼ˆå¦‚æŠ–éŸ³ã€å°çº¢ä¹¦ç­‰ï¼‰
            cleaned_url = url

            # ç§»é™¤å¸¸è§çš„åˆ†äº«æ–‡æœ¬å‰ç¼€
            import re
            # åŒ¹é…ç±»ä¼¼ "4 ã€AUGè‡ªè¿° - æ­¦å™¨å¤§å¸ˆ | å°çº¢ä¹¦ - ä½ çš„ç”Ÿæ´»å…´è¶£ç¤¾åŒºã€‘ ğŸ˜† HIbzka9uzjpGbxB ğŸ˜† https://www.xiaohongshu.com/..."
            pattern = r'.*?(https?://[^\s]+)'
            match = re.search(pattern, url)
            if match:
                cleaned_url = match.group(1)

            parsed = urlparse(cleaned_url)

            # å¤„ç†Bç«™é“¾æ¥
            if 'bilibili.com' in parsed.netloc.lower() or 'b23.tv' in parsed.netloc.lower():
                # æ¸…ç†Bç«™URLï¼Œç§»é™¤ä¸å¿…è¦çš„è·Ÿè¸ªå‚æ•°
                path = parsed.path
                query_params = {}

                # ä¿ç•™é‡è¦çš„æŸ¥è¯¢å‚æ•°
                if parsed.query:
                    for param in ['p', 't', 'dm']:  # ä¿ç•™é¡µç ã€æ—¶é—´æˆ³ã€å¼¹å¹•å¼€å…³ç­‰
                        if param in parsed.query:
                            query_params[param] = parsed.query.split(f'{param}=')[1].split('&')[0]

                # é‡å»ºå¹²å‡€çš„URL
                clean_url = f"https://www.bilibili.com{path}"
                if query_params:
                    query_string = "&".join([f"{k}={v}" for k, v in query_params.items()])
                    clean_url += f"?{query_string}"

                # å¤„ç†çŸ­é“¾æ¥é‡å®šå‘
                if 'b23.tv' in parsed.netloc.lower():
                    try:
                        response = requests.head(url, allow_redirects=True, timeout=10,
                                               headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'})
                        if response.status_code == 200 and 'bilibili.com' in response.url:
                            return response.url
                    except Exception:
                        pass

                return clean_url

            # å¤„ç†YouTubeçŸ­é“¾æ¥
            elif 'youtu.be' in parsed.netloc.lower():
                try:
                    response = requests.head(url, allow_redirects=True, timeout=10,
                                           headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'})
                    if response.status_code == 200:
                        return response.url
                except Exception:
                    pass

            # å¤„ç†å°çº¢ä¹¦é“¾æ¥ï¼Œä¿ç•™å¿…è¦çš„è®¿é—®å‚æ•°
            elif 'xiaohongshu.com' in parsed.netloc.lower():
                # å°çº¢ä¹¦é“¾æ¥éœ€è¦ç‰¹å®šå‚æ•°æ‰èƒ½è®¿é—®ï¼Œå¿…é¡»ä¿ç•™è¿™äº›å‚æ•°
                path = parsed.path
                query_params = {}

                # è§£ææŸ¥è¯¢å‚æ•°
                if parsed.query:
                    for param in parsed.query.split('&'):
                        if '=' in param:
                            key, value = param.split('=', 1)
                            # ä¿ç•™å¯¹è®¿é—®è‡³å…³é‡è¦çš„å‚æ•°
                            if key in ['source', 'xhsshare', 'xsec_token', 'xsec_source']:
                                query_params[key] = value

                # é‡å»ºURLï¼Œä¿ç•™å¿…è¦çš„å‚æ•°
                clean_url = f"https://www.xiaohongshu.com{path}"
                if query_params:
                    query_string = "&".join([f"{k}={v}" for k, v in query_params.items()])
                    clean_url += f"?{query_string}"

                return clean_url

            return cleaned_url
        except Exception:
            return url

    def get_video_info(self, url: str) -> Dict:
        """è·å–è§†é¢‘ä¿¡æ¯è€Œä¸ä¸‹è½½"""
        try:
            # é¢„å¤„ç†URL
            processed_url = self.preprocess_url(url)
            platform = self.detect_platform(processed_url)

            # é’ˆå¯¹Bç«™ä½¿ç”¨ç‰¹æ®Šé…ç½®
            if platform == 'bilibili':
                opts = self.get_bilibili_opts({'quiet': True}, download_mode=False)
                try:
                    with yt_dlp.YoutubeDL(opts) as ydl:
                        info = ydl.extract_info(processed_url, download=False)
                except Exception as e:
                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ›´å®½æ¾çš„é…ç½®
                    print(f"Bç«™ä¿¡æ¯è·å–å¤±è´¥ï¼Œå°è¯•å®½æ¾é…ç½®: {str(e)}")
                    relaxed_opts = self.get_bilibili_opts({'quiet': False, 'ignoreerrors': True}, download_mode=False)
                    with yt_dlp.YoutubeDL(relaxed_opts) as ydl:
                        info = ydl.extract_info(processed_url, download=False)
            else:
                # å…¶ä»–å¹³å°ä½¿ç”¨é»˜è®¤é…ç½®
                with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
                    info = ydl.extract_info(processed_url, download=False)

            if info is None:
                raise Exception('æ— æ³•è·å–è§†é¢‘ä¿¡æ¯')

            return {
                'title': info.get('title', ''),
                'description': info.get('description', ''),
                'duration': info.get('duration', 0),
                'view_count': info.get('view_count', 0),
                'uploader': info.get('uploader', ''),
                'upload_date': info.get('upload_date', ''),
                'thumbnail': info.get('thumbnail', ''),
                'platform': platform,
                'original_url': url,
                'processed_url': processed_url
            }
        except Exception as e:
            raise Exception(f'è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}')